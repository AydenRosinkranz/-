! pip install xlsxwriter
! pip install transformers
import pandas as pd
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import pandas as pd
import numpy as np

# Load the pre-trained BERT model and tokenizer
model_name_or_path = "bert-base-chinese"
tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)
model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path)
from google.colab import drive
drive.mount('/content/drive')
# Read the input Excel file containing Chinese text data
input_file = "testdemo.xlsx"
output_file_name = 'testscore.xlsx'
file_name = '/content/drive/MyDrive/testdemo.xlsx'
excel_file = pd.ExcelFile(file_name)
sheet_names = excel_file.sheet_names
writer = pd.ExcelWriter(output_file_name,engine='xlsxwriter')
for sheet_name in sheet_names:
  data = pd.read_excel(excel_file,sheet_name = sheet_name).astype(str)
  for column in data.columns:
    encoded_data = tokenizer(data[column].tolist(), padding=True, truncation=True, max_length=128, return_tensors="pt")
    output = model(**encoded_data)
    scores = output.logits.softmax(dim=-1).tolist()
    data[column+'testscore'] = [score[1] for score in scores]
  data.to_excel(writer, sheet_name=sheet_name, index=False)
writer.close()
